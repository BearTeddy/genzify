{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "dictionary_path = pkg_resources.resource_filename(\n",
    "    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\"\n",
    ")\n",
    "# term_index is the column of the term and count_index is the\n",
    "# column of the term frequency\n",
    "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "\n",
    "\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download en_core_web_lg\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "nlp.add_pipe(\"emoji\", first=True)\n",
    "st = SnowballStemmer('english')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to Achive the Solution:\n",
    "    Text lowercasing\n",
    "    Tokenization\n",
    "    Stop-word removal\n",
    "    Handling Numerical values\n",
    "    Handling Special characters\n",
    "    Whitespace stripping\n",
    "    Lemmatization/Stemming\n",
    "    Spelling correction\n",
    "    Part-of -Speech tagging\n",
    "    Handling Contractions\n",
    "    Removal of short/rare words\n",
    "    Text encoding/ Vectorization\n",
    "    Padding/Truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''' Zero is a beautiful number. Not because it is round and cute (that could be an argument for it nevertheless) but because what it signifies. It marks the beginning of something. It marks the lowest something, or someone can go. It is the ultimate foundation to build anything upon.\n",
    "\n",
    "Over last several years, I‚Äôve started several things from scratch and have failed at many (thus going back to zero), and I‚Äôve realized there‚Äôs nothing more liberating than being at zero because the only way from zero is upwards. A very good friend once told me, ‚ÄúDon‚Äôt worry if you‚Äôve failed. Rockets that touch the sky always launch from the ground.‚Äù\n",
    "\n",
    " üòÇüòÇ  As J K Rowling, one of my favorite authors says, ‚ÄúRock bottom became the solid foundation on which I rebuilt my life.‚Äù\n",
    "\n",
    "While zero is liberating, thrilling and exciting, it sometimes also is daunting and overwhelming. Sometimes, I have found myself afraid to do something because I was comfortable being at zero and the task to go from zero to one seemed unnerving. This challenge of writing twenty-six stories was one such adventure. I remember it was the first of April when I decided to pen down a story for each letter of the alphabet. I was afraid if I was unknowingly planning to fool myself on April 1st.\n",
    "\n",
    "I had no clue what to write even for the first letter of the alphabet. I was afraid I‚Äôd ruin twenty-six stories if I begin writing them just for the sake of writing.\n",
    "\n",
    "What gave me the courage to take up ü§ê the challenge was to lower the expectations that I‚Äôd have from these stories. My purpose was not to write twenty-six bestseller stories. Mine was to make it a habit of writing every day. Some days everything that came out of my pen was garbage, and on a few days, I loved what my hands typed on the blank paper. And today, with this last story, I am back at zero ‚Äî a solid foundation for the next adventure.\n",
    "\n",
    "Writing has become my daily habit, and I can remember to write even without my calendar sending me a reminder. I am curious what could I make out of this habit. Shall I start another writing adventure? Will it be a similar series? Will be a novel (long due now)? Or something different altogether?\n",
    "\n",
    "Whatever it‚Äôd be, I guess I‚Äôll be little less nervous to begin whatever comes next. I am at zero again, and the only way to go from here is upwards. Realizing that there‚Äôll be one less thing in my daily routine, I feel a particular kind of guilt. It‚Äôs the kind of guilt that you feel when you have an ice-cream without telling your younger sibling about it. You kind of like it that you had the ice-cream but also feel guilty for hiding it from them.\n",
    "\n",
    "On the new adventure, whatever it‚Äôd be, it‚Äôs time to buy an ice-cream for them this time. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentences \n",
    "text = nlp(text)\n",
    "# type(text)\n",
    "sentences = list(text.sents)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (1654898104.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    def lower_spellcheck_english_emoji(wor\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "# Spell Checking\n",
    "english_words = set(words.words())\n",
    "\n",
    "def lower_spellcheck_english_emoji(sentence):\n",
    "    \n",
    "    word = word.lower()\n",
    "    #if wrong spelling, correct it\n",
    "    if word not in english_words:\n",
    "        \n",
    "    return word.lower() in english_words or not word.isalpha() or word.isascii()\n",
    "\n",
    "corrected_tokens = [word for word in tokens if word.lower() in english_words or not word.isalpha() or word.i]\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in english_tokens]\n",
    "\n",
    "# Join the tokens back into a string\n",
    "preprocessed_text = ' '.join(lemmatized_tokens)\n",
    "\n",
    "print(preprocessed_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genzify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
